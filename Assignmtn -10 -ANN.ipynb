{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(r\"C:\\Users\\PRAKASH KATIKANENI\\Downloads\\50_startups.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.2</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.7</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0   165349.2       136897.80        471784.10    New York  192261.83\n",
       "1   162597.7       151377.59        443898.53  California  191792.06"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R&D Spend          False\n",
       "Administration     False\n",
       "Marketing Spend    False\n",
       "State              False\n",
       "Profit             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "dataset['State']=le.fit_transform(dataset['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>2</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>0</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>1</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>2</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>1</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend  State     Profit\n",
       "0  165349.20       136897.80        471784.10      2  192261.83\n",
       "1  162597.70       151377.59        443898.53      0  191792.06\n",
       "2  153441.51       101145.55        407934.54      1  191050.39\n",
       "3  144372.41       118671.85        383199.62      2  182901.99\n",
       "4  142107.34        91391.77        366168.42      1  166187.94"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataset.iloc[:,0:4].values\n",
    "y=dataset.iloc[:,4:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one=OneHotEncoder()\n",
    "z=one.fit_transform(x[:,3:4]).toarray()\n",
    "x=np.delete(x,3,axis=1)\n",
    "x=np.concatenate((z,x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train ,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=6, activation=\"relu\", kernel_initializer=\"random_uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "regressor.add(Dense(units = 6,init = 'random_uniform',activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=12, activation=\"relu\", kernel_initializer=\"random_uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "regressor.add(Dense(units = 12,init = 'random_uniform',activation = 'relu')) \n",
    "#first hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=8, activation=\"relu\", kernel_initializer=\"random_uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "regressor.add(Dense(units = 8,init = 'random_uniform',activation = 'relu'))\n",
    "#second hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=9, activation=\"relu\", kernel_initializer=\"random_uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "regressor.add(Dense(units = 9,init = 'random_uniform',activation = 'relu'))\n",
    "#third hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"random_uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "regressor.add(Dense(units = 1,init = 'random_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile (optimizer = 'adam',loss = 'mse',metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PRAKASH KATIKANENI\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/300\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 13615995648.0000 - mse: 13615995904.0000\n",
      "Epoch 2/300\n",
      "40/40 [==============================] - 0s 485us/step - loss: 13615994880.0000 - mse: 13615994880.0000\n",
      "Epoch 3/300\n",
      "40/40 [==============================] - 0s 380us/step - loss: 13615992064.0000 - mse: 13615991808.0000\n",
      "Epoch 4/300\n",
      "40/40 [==============================] - 0s 258us/step - loss: 13615989248.0000 - mse: 13615988736.0000\n",
      "Epoch 5/300\n",
      "40/40 [==============================] - 0s 303us/step - loss: 13615981312.0000 - mse: 13615981568.0000\n",
      "Epoch 6/300\n",
      "40/40 [==============================] - 0s 344us/step - loss: 13615962112.0000 - mse: 13615962112.0000\n",
      "Epoch 7/300\n",
      "40/40 [==============================] - 0s 255us/step - loss: 13615917568.0000 - mse: 13615917056.0000\n",
      "Epoch 8/300\n",
      "40/40 [==============================] - 0s 310us/step - loss: 13615827200.0000 - mse: 13615826944.0000\n",
      "Epoch 9/300\n",
      "40/40 [==============================] - 0s 332us/step - loss: 13615620096.0000 - mse: 13615620096.0000\n",
      "Epoch 10/300\n",
      "40/40 [==============================] - 0s 287us/step - loss: 13615218176.0000 - mse: 13615217664.0000\n",
      "Epoch 11/300\n",
      "40/40 [==============================] - 0s 373us/step - loss: 13614446848.0000 - mse: 13614446592.0000\n",
      "Epoch 12/300\n",
      "40/40 [==============================] - 0s 279us/step - loss: 13612975616.0000 - mse: 13612976128.0000\n",
      "Epoch 13/300\n",
      "40/40 [==============================] - 0s 327us/step - loss: 13610250240.0000 - mse: 13610251264.0000\n",
      "Epoch 14/300\n",
      "40/40 [==============================] - 0s 352us/step - loss: 13605624064.0000 - mse: 13605623808.0000\n",
      "Epoch 15/300\n",
      "40/40 [==============================] - 0s 332us/step - loss: 13598372864.0000 - mse: 13598372864.0000\n",
      "Epoch 16/300\n",
      "40/40 [==============================] - 0s 319us/step - loss: 13586001664.0000 - mse: 13586001920.0000\n",
      "Epoch 17/300\n",
      "40/40 [==============================] - 0s 253us/step - loss: 13565705728.0000 - mse: 13565705216.0000\n",
      "Epoch 18/300\n",
      "40/40 [==============================] - 0s 354us/step - loss: 13534919680.0000 - mse: 13534918656.0000\n",
      "Epoch 19/300\n",
      "40/40 [==============================] - 0s 352us/step - loss: 13487696128.0000 - mse: 13487695872.0000\n",
      "Epoch 20/300\n",
      "40/40 [==============================] - 0s 406us/step - loss: 13419173376.0000 - mse: 13419173888.0000\n",
      "Epoch 21/300\n",
      "40/40 [==============================] - 0s 407us/step - loss: 13315943424.0000 - mse: 13315943424.0000\n",
      "Epoch 22/300\n",
      "40/40 [==============================] - 0s 212us/step - loss: 13184565248.0000 - mse: 13184565248.0000\n",
      "Epoch 23/300\n",
      "40/40 [==============================] - 0s 221us/step - loss: 13001545728.0000 - mse: 13001545728.0000\n",
      "Epoch 24/300\n",
      "40/40 [==============================] - 0s 256us/step - loss: 12721053952.0000 - mse: 12721053696.0000\n",
      "Epoch 25/300\n",
      "40/40 [==============================] - 0s 316us/step - loss: 12375179776.0000 - mse: 12375180288.0000\n",
      "Epoch 26/300\n",
      "40/40 [==============================] - 0s 265us/step - loss: 11875123200.0000 - mse: 11875123200.0000\n",
      "Epoch 27/300\n",
      "40/40 [==============================] - 0s 257us/step - loss: 11300499456.0000 - mse: 11300499456.0000\n",
      "Epoch 28/300\n",
      "40/40 [==============================] - 0s 257us/step - loss: 10539982720.0000 - mse: 10539982848.0000\n",
      "Epoch 29/300\n",
      "40/40 [==============================] - 0s 293us/step - loss: 9520892288.0000 - mse: 9520891904.0000\n",
      "Epoch 30/300\n",
      "40/40 [==============================] - 0s 276us/step - loss: 8375243904.0000 - mse: 8375243776.0000\n",
      "Epoch 31/300\n",
      "40/40 [==============================] - 0s 289us/step - loss: 6984839680.0000 - mse: 6984840192.0000\n",
      "Epoch 32/300\n",
      "40/40 [==============================] - 0s 352us/step - loss: 5521294208.0000 - mse: 5521294336.0000\n",
      "Epoch 33/300\n",
      "40/40 [==============================] - 0s 234us/step - loss: 3839016768.0000 - mse: 3839016960.0000\n",
      "Epoch 34/300\n",
      "40/40 [==============================] - 0s 296us/step - loss: 2380228224.0000 - mse: 2380228096.0000\n",
      "Epoch 35/300\n",
      "40/40 [==============================] - 0s 365us/step - loss: 1222841408.0000 - mse: 1222841344.0000\n",
      "Epoch 36/300\n",
      "40/40 [==============================] - 0s 324us/step - loss: 546774872.0000 - mse: 546774912.0000\n",
      "Epoch 37/300\n",
      "40/40 [==============================] - 0s 193us/step - loss: 444904096.0000 - mse: 444904096.0000\n",
      "Epoch 38/300\n",
      "40/40 [==============================] - 0s 323us/step - loss: 621571344.0000 - mse: 621571392.0000\n",
      "Epoch 39/300\n",
      "40/40 [==============================] - 0s 220us/step - loss: 652750920.0000 - mse: 652750976.0000\n",
      "Epoch 40/300\n",
      "40/40 [==============================] - 0s 185us/step - loss: 542799736.0000 - mse: 542799744.0000\n",
      "Epoch 41/300\n",
      "40/40 [==============================] - 0s 263us/step - loss: 407174936.0000 - mse: 407174976.0000\n",
      "Epoch 42/300\n",
      "40/40 [==============================] - 0s 296us/step - loss: 393504708.0000 - mse: 393504704.0000\n",
      "Epoch 43/300\n",
      "40/40 [==============================] - 0s 331us/step - loss: 396967876.0000 - mse: 396967872.0000\n",
      "Epoch 44/300\n",
      "40/40 [==============================] - 0s 279us/step - loss: 405679208.0000 - mse: 405679200.0000\n",
      "Epoch 45/300\n",
      "40/40 [==============================] - 0s 295us/step - loss: 397746116.0000 - mse: 397746112.0000\n",
      "Epoch 46/300\n",
      "40/40 [==============================] - 0s 280us/step - loss: 382979548.0000 - mse: 382979520.0000\n",
      "Epoch 47/300\n",
      "40/40 [==============================] - 0s 289us/step - loss: 369652736.0000 - mse: 369652736.0000\n",
      "Epoch 48/300\n",
      "40/40 [==============================] - 0s 324us/step - loss: 368605960.0000 - mse: 368605952.0000\n",
      "Epoch 49/300\n",
      "40/40 [==============================] - 0s 291us/step - loss: 367535212.0000 - mse: 367535232.0000\n",
      "Epoch 50/300\n",
      "40/40 [==============================] - 0s 231us/step - loss: 367257992.0000 - mse: 367257984.0000\n",
      "Epoch 51/300\n",
      "40/40 [==============================] - 0s 271us/step - loss: 364316724.0000 - mse: 364316736.0000\n",
      "Epoch 52/300\n",
      "40/40 [==============================] - 0s 330us/step - loss: 360130136.0000 - mse: 360130112.0000\n",
      "Epoch 53/300\n",
      "40/40 [==============================] - 0s 286us/step - loss: 357996096.0000 - mse: 357996096.0000\n",
      "Epoch 54/300\n",
      "40/40 [==============================] - 0s 262us/step - loss: 355665968.0000 - mse: 355665984.0000\n",
      "Epoch 55/300\n",
      "40/40 [==============================] - 0s 252us/step - loss: 353983196.0000 - mse: 353983200.0000\n",
      "Epoch 56/300\n",
      "40/40 [==============================] - 0s 197us/step - loss: 351653324.0000 - mse: 351653312.0000\n",
      "Epoch 57/300\n",
      "40/40 [==============================] - 0s 185us/step - loss: 348886210.0000 - mse: 348886208.0000\n",
      "Epoch 58/300\n",
      "40/40 [==============================] - 0s 112us/step - loss: 347119960.0000 - mse: 347119968.0000\n",
      "Epoch 59/300\n",
      "40/40 [==============================] - 0s 193us/step - loss: 347154244.0000 - mse: 347154240.0000\n",
      "Epoch 60/300\n",
      "40/40 [==============================] - 0s 297us/step - loss: 343366375.0000 - mse: 343366368.0000\n",
      "Epoch 61/300\n",
      "40/40 [==============================] - 0s 258us/step - loss: 340596840.0000 - mse: 340596832.0000\n",
      "Epoch 62/300\n",
      "40/40 [==============================] - 0s 313us/step - loss: 340606412.0000 - mse: 340606400.0000\n",
      "Epoch 63/300\n",
      "40/40 [==============================] - 0s 164us/step - loss: 338442304.0000 - mse: 338442304.0000\n",
      "Epoch 64/300\n",
      "40/40 [==============================] - 0s 247us/step - loss: 335477856.0000 - mse: 335477856.0000\n",
      "Epoch 65/300\n",
      "40/40 [==============================] - 0s 290us/step - loss: 335187600.0000 - mse: 335187616.0000\n",
      "Epoch 66/300\n",
      "40/40 [==============================] - 0s 243us/step - loss: 331236728.0000 - mse: 331236704.0000\n",
      "Epoch 67/300\n",
      "40/40 [==============================] - 0s 278us/step - loss: 328606524.0000 - mse: 328606528.0000\n",
      "Epoch 68/300\n",
      "40/40 [==============================] - 0s 223us/step - loss: 328140453.0000 - mse: 328140480.0000\n",
      "Epoch 69/300\n",
      "40/40 [==============================] - 0s 178us/step - loss: 323973472.0000 - mse: 323973472.0000\n",
      "Epoch 70/300\n",
      "40/40 [==============================] - 0s 189us/step - loss: 322506308.0000 - mse: 322506304.0000\n",
      "Epoch 71/300\n",
      "40/40 [==============================] - 0s 231us/step - loss: 321752612.0000 - mse: 321752608.0000\n",
      "Epoch 72/300\n",
      "40/40 [==============================] - 0s 381us/step - loss: 318479188.0000 - mse: 318479200.0000\n",
      "Epoch 73/300\n",
      "40/40 [==============================] - 0s 355us/step - loss: 316846460.0000 - mse: 316846432.0000\n",
      "Epoch 74/300\n",
      "40/40 [==============================] - 0s 247us/step - loss: 314965142.0000 - mse: 314965152.0000\n",
      "Epoch 75/300\n",
      "40/40 [==============================] - 0s 302us/step - loss: 313939184.0000 - mse: 313939168.0000\n",
      "Epoch 76/300\n",
      "40/40 [==============================] - 0s 281us/step - loss: 312370988.0000 - mse: 312371008.0000\n",
      "Epoch 77/300\n",
      "40/40 [==============================] - 0s 361us/step - loss: 310067680.0000 - mse: 310067648.0000\n",
      "Epoch 78/300\n",
      "40/40 [==============================] - 0s 332us/step - loss: 307059376.0000 - mse: 307059360.0000\n",
      "Epoch 79/300\n",
      "40/40 [==============================] - 0s 344us/step - loss: 306524510.0000 - mse: 306524512.0000\n",
      "Epoch 80/300\n",
      "40/40 [==============================] - 0s 275us/step - loss: 303113240.0000 - mse: 303113216.0000\n",
      "Epoch 81/300\n",
      "40/40 [==============================] - 0s 354us/step - loss: 301948048.0000 - mse: 301948064.0000\n",
      "Epoch 82/300\n",
      "40/40 [==============================] - 0s 357us/step - loss: 299492108.0000 - mse: 299492096.0000\n",
      "Epoch 83/300\n",
      "40/40 [==============================] - 0s 250us/step - loss: 298580639.0000 - mse: 298580608.0000\n",
      "Epoch 84/300\n",
      "40/40 [==============================] - 0s 361us/step - loss: 296264312.0000 - mse: 296264288.0000\n",
      "Epoch 85/300\n",
      "40/40 [==============================] - 0s 335us/step - loss: 294430252.0000 - mse: 294430272.0000\n",
      "Epoch 86/300\n",
      "40/40 [==============================] - 0s 338us/step - loss: 292350592.0000 - mse: 292350560.0000\n",
      "Epoch 87/300\n",
      "40/40 [==============================] - 0s 339us/step - loss: 290462604.0000 - mse: 290462624.0000\n",
      "Epoch 88/300\n",
      "40/40 [==============================] - 0s 323us/step - loss: 288996360.0000 - mse: 288996352.0000\n",
      "Epoch 89/300\n",
      "40/40 [==============================] - 0s 339us/step - loss: 287442292.0000 - mse: 287442272.0000\n",
      "Epoch 90/300\n",
      "40/40 [==============================] - 0s 335us/step - loss: 285384938.0000 - mse: 285384928.0000\n",
      "Epoch 91/300\n",
      "40/40 [==============================] - 0s 275us/step - loss: 283758244.0000 - mse: 283758240.0000\n",
      "Epoch 92/300\n",
      "40/40 [==============================] - 0s 302us/step - loss: 282952960.0000 - mse: 282952960.0000\n",
      "Epoch 93/300\n",
      "40/40 [==============================] - 0s 311us/step - loss: 280553078.0000 - mse: 280553088.0000\n",
      "Epoch 94/300\n",
      "40/40 [==============================] - 0s 254us/step - loss: 278598124.0000 - mse: 278598144.0000\n",
      "Epoch 95/300\n",
      "40/40 [==============================] - 0s 238us/step - loss: 277385788.0000 - mse: 277385792.0000\n",
      "Epoch 96/300\n",
      "40/40 [==============================] - 0s 274us/step - loss: 275331720.0000 - mse: 275331744.0000\n",
      "Epoch 97/300\n",
      "40/40 [==============================] - 0s 327us/step - loss: 274584330.0000 - mse: 274584320.0000\n",
      "Epoch 98/300\n",
      "40/40 [==============================] - 0s 294us/step - loss: 272571100.0000 - mse: 272571104.0000\n",
      "Epoch 99/300\n",
      "40/40 [==============================] - 0s 298us/step - loss: 271780636.0000 - mse: 271780640.0000\n",
      "Epoch 100/300\n",
      "40/40 [==============================] - 0s 190us/step - loss: 269822964.0000 - mse: 269822976.0000\n",
      "Epoch 101/300\n",
      "40/40 [==============================] - 0s 202us/step - loss: 270113494.0000 - mse: 270113472.0000\n",
      "Epoch 102/300\n",
      "40/40 [==============================] - 0s 210us/step - loss: 266159008.0000 - mse: 266159024.0000\n",
      "Epoch 103/300\n",
      "40/40 [==============================] - 0s 196us/step - loss: 264413884.0000 - mse: 264413872.0000\n",
      "Epoch 104/300\n",
      "40/40 [==============================] - 0s 248us/step - loss: 263449860.0000 - mse: 263449856.0000\n",
      "Epoch 105/300\n",
      "40/40 [==============================] - 0s 199us/step - loss: 261196536.0000 - mse: 261196512.0000\n",
      "Epoch 106/300\n",
      "40/40 [==============================] - 0s 253us/step - loss: 260038096.0000 - mse: 260038096.0000\n",
      "Epoch 107/300\n",
      "40/40 [==============================] - 0s 304us/step - loss: 259199260.0000 - mse: 259199264.0000\n",
      "Epoch 108/300\n",
      "40/40 [==============================] - 0s 361us/step - loss: 256625622.0000 - mse: 256625632.0000\n",
      "Epoch 109/300\n",
      "40/40 [==============================] - 0s 351us/step - loss: 256367836.0000 - mse: 256367872.0000\n",
      "Epoch 110/300\n",
      "40/40 [==============================] - 0s 326us/step - loss: 255100964.0000 - mse: 255100976.0000\n",
      "Epoch 111/300\n",
      "40/40 [==============================] - 0s 308us/step - loss: 253857432.0000 - mse: 253857440.0000\n",
      "Epoch 112/300\n",
      "40/40 [==============================] - 0s 317us/step - loss: 251663264.0000 - mse: 251663264.0000\n",
      "Epoch 113/300\n",
      "40/40 [==============================] - 0s 295us/step - loss: 249708286.0000 - mse: 249708288.0000\n",
      "Epoch 114/300\n",
      "40/40 [==============================] - 0s 308us/step - loss: 248447748.0000 - mse: 248447744.0000\n",
      "Epoch 115/300\n",
      "40/40 [==============================] - 0s 196us/step - loss: 247111274.0000 - mse: 247111264.0000\n",
      "Epoch 116/300\n",
      "40/40 [==============================] - 0s 262us/step - loss: 246155202.0000 - mse: 246155216.0000\n",
      "Epoch 117/300\n",
      "40/40 [==============================] - 0s 244us/step - loss: 246014656.0000 - mse: 246014640.0000\n",
      "Epoch 118/300\n",
      "40/40 [==============================] - 0s 144us/step - loss: 244004308.0000 - mse: 244004304.0000\n",
      "Epoch 119/300\n",
      "40/40 [==============================] - 0s 181us/step - loss: 242138220.0000 - mse: 242138208.0000\n",
      "Epoch 120/300\n",
      "40/40 [==============================] - 0s 314us/step - loss: 240493822.0000 - mse: 240493824.0000\n",
      "Epoch 121/300\n",
      "40/40 [==============================] - 0s 235us/step - loss: 241635768.0000 - mse: 241635760.0000\n",
      "Epoch 122/300\n",
      "40/40 [==============================] - 0s 251us/step - loss: 238199316.0000 - mse: 238199328.0000\n",
      "Epoch 123/300\n",
      "40/40 [==============================] - 0s 187us/step - loss: 237092692.0000 - mse: 237092704.0000\n",
      "Epoch 124/300\n",
      "40/40 [==============================] - 0s 120us/step - loss: 235861482.0000 - mse: 235861504.0000\n",
      "Epoch 125/300\n",
      "40/40 [==============================] - 0s 154us/step - loss: 234951268.0000 - mse: 234951264.0000\n",
      "Epoch 126/300\n",
      "40/40 [==============================] - 0s 239us/step - loss: 233356128.0000 - mse: 233356128.0000\n",
      "Epoch 127/300\n",
      "40/40 [==============================] - 0s 206us/step - loss: 231706210.0000 - mse: 231706208.0000\n",
      "Epoch 128/300\n",
      "40/40 [==============================] - 0s 137us/step - loss: 231217568.0000 - mse: 231217568.0000\n",
      "Epoch 129/300\n",
      "40/40 [==============================] - 0s 206us/step - loss: 230024352.0000 - mse: 230024352.0000\n",
      "Epoch 130/300\n",
      "40/40 [==============================] - 0s 271us/step - loss: 228266244.0000 - mse: 228266240.0000\n",
      "Epoch 131/300\n",
      "40/40 [==============================] - 0s 195us/step - loss: 227631690.0000 - mse: 227631696.0000\n",
      "Epoch 132/300\n",
      "40/40 [==============================] - 0s 207us/step - loss: 226386772.0000 - mse: 226386784.0000\n",
      "Epoch 133/300\n",
      "40/40 [==============================] - 0s 247us/step - loss: 225167772.0000 - mse: 225167776.0000\n",
      "Epoch 134/300\n",
      "40/40 [==============================] - 0s 209us/step - loss: 224078304.0000 - mse: 224078304.0000\n",
      "Epoch 135/300\n",
      "40/40 [==============================] - 0s 165us/step - loss: 223111354.0000 - mse: 223111328.0000\n",
      "Epoch 136/300\n",
      "40/40 [==============================] - 0s 238us/step - loss: 221565780.0000 - mse: 221565776.0000\n",
      "Epoch 137/300\n",
      "40/40 [==============================] - 0s 230us/step - loss: 221150348.0000 - mse: 221150368.0000\n",
      "Epoch 138/300\n",
      "40/40 [==============================] - 0s 195us/step - loss: 219491402.0000 - mse: 219491376.0000\n",
      "Epoch 139/300\n",
      "40/40 [==============================] - 0s 178us/step - loss: 219411440.0000 - mse: 219411456.0000\n",
      "Epoch 140/300\n",
      "40/40 [==============================] - 0s 231us/step - loss: 217073276.0000 - mse: 217073280.0000\n",
      "Epoch 141/300\n",
      "40/40 [==============================] - 0s 284us/step - loss: 216992430.0000 - mse: 216992432.0000\n",
      "Epoch 142/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 292us/step - loss: 215158124.0000 - mse: 215158112.0000\n",
      "Epoch 143/300\n",
      "40/40 [==============================] - 0s 242us/step - loss: 216115922.0000 - mse: 216115920.0000\n",
      "Epoch 144/300\n",
      "40/40 [==============================] - 0s 262us/step - loss: 213304244.0000 - mse: 213304240.0000\n",
      "Epoch 145/300\n",
      "40/40 [==============================] - 0s 208us/step - loss: 213859492.0000 - mse: 213859488.0000\n",
      "Epoch 146/300\n",
      "40/40 [==============================] - 0s 226us/step - loss: 212576480.0000 - mse: 212576480.0000\n",
      "Epoch 147/300\n",
      "40/40 [==============================] - 0s 256us/step - loss: 211392456.0000 - mse: 211392464.0000\n",
      "Epoch 148/300\n",
      "40/40 [==============================] - 0s 315us/step - loss: 209970820.0000 - mse: 209970832.0000\n",
      "Epoch 149/300\n",
      "40/40 [==============================] - 0s 307us/step - loss: 209261000.0000 - mse: 209261008.0000\n",
      "Epoch 150/300\n",
      "40/40 [==============================] - 0s 307us/step - loss: 207629162.5000 - mse: 207629152.0000\n",
      "Epoch 151/300\n",
      "40/40 [==============================] - 0s 134us/step - loss: 207877554.0000 - mse: 207877552.0000\n",
      "Epoch 152/300\n",
      "40/40 [==============================] - 0s 267us/step - loss: 207612202.0000 - mse: 207612208.0000\n",
      "Epoch 153/300\n",
      "40/40 [==============================] - 0s 257us/step - loss: 205554344.0000 - mse: 205554336.0000\n",
      "Epoch 154/300\n",
      "40/40 [==============================] - 0s 190us/step - loss: 205453870.0000 - mse: 205453872.0000\n",
      "Epoch 155/300\n",
      "40/40 [==============================] - 0s 228us/step - loss: 204574292.0000 - mse: 204574288.0000\n",
      "Epoch 156/300\n",
      "40/40 [==============================] - 0s 271us/step - loss: 202754902.0000 - mse: 202754912.0000\n",
      "Epoch 157/300\n",
      "40/40 [==============================] - 0s 281us/step - loss: 201866460.0000 - mse: 201866464.0000\n",
      "Epoch 158/300\n",
      "40/40 [==============================] - 0s 237us/step - loss: 203068624.0000 - mse: 203068624.0000\n",
      "Epoch 159/300\n",
      "40/40 [==============================] - 0s 202us/step - loss: 200418984.0000 - mse: 200418976.0000\n",
      "Epoch 160/300\n",
      "40/40 [==============================] - 0s 252us/step - loss: 199309170.0000 - mse: 199309152.0000\n",
      "Epoch 161/300\n",
      "40/40 [==============================] - 0s 220us/step - loss: 198171870.0000 - mse: 198171872.0000\n",
      "Epoch 162/300\n",
      "40/40 [==============================] - 0s 205us/step - loss: 197343984.0000 - mse: 197343984.0000\n",
      "Epoch 163/300\n",
      "40/40 [==============================] - 0s 276us/step - loss: 196851058.0000 - mse: 196851056.0000\n",
      "Epoch 164/300\n",
      "40/40 [==============================] - 0s 193us/step - loss: 196299088.0000 - mse: 196299088.0000\n",
      "Epoch 165/300\n",
      "40/40 [==============================] - 0s 231us/step - loss: 195216680.0000 - mse: 195216688.0000\n",
      "Epoch 166/300\n",
      "40/40 [==============================] - 0s 226us/step - loss: 194430392.0000 - mse: 194430384.0000\n",
      "Epoch 167/300\n",
      "40/40 [==============================] - 0s 287us/step - loss: 194301568.0000 - mse: 194301568.0000\n",
      "Epoch 168/300\n",
      "40/40 [==============================] - 0s 250us/step - loss: 195252873.0000 - mse: 195252880.0000\n",
      "Epoch 169/300\n",
      "40/40 [==============================] - 0s 237us/step - loss: 194239304.0000 - mse: 194239312.0000\n",
      "Epoch 170/300\n",
      "40/40 [==============================] - 0s 318us/step - loss: 192252504.0000 - mse: 192252512.0000\n",
      "Epoch 171/300\n",
      "40/40 [==============================] - 0s 206us/step - loss: 190738526.0000 - mse: 190738528.0000\n",
      "Epoch 172/300\n",
      "40/40 [==============================] - ETA: 0s - loss: 162717408.0000 - mse: 162717408.000 - 0s 254us/step - loss: 191856540.0000 - mse: 191856544.0000\n",
      "Epoch 173/300\n",
      "40/40 [==============================] - 0s 234us/step - loss: 189766442.0000 - mse: 189766448.0000\n",
      "Epoch 174/300\n",
      "40/40 [==============================] - 0s 233us/step - loss: 188301496.0000 - mse: 188301488.0000\n",
      "Epoch 175/300\n",
      "40/40 [==============================] - 0s 253us/step - loss: 187424892.0000 - mse: 187424896.0000\n",
      "Epoch 176/300\n",
      "40/40 [==============================] - 0s 228us/step - loss: 187825440.0000 - mse: 187825440.0000\n",
      "Epoch 177/300\n",
      "40/40 [==============================] - 0s 240us/step - loss: 188289828.0000 - mse: 188289824.0000\n",
      "Epoch 178/300\n",
      "40/40 [==============================] - 0s 247us/step - loss: 185999440.0000 - mse: 185999456.0000\n",
      "Epoch 179/300\n",
      "40/40 [==============================] - 0s 204us/step - loss: 185953206.0000 - mse: 185953200.0000\n",
      "Epoch 180/300\n",
      "40/40 [==============================] - 0s 175us/step - loss: 185321064.0000 - mse: 185321056.0000\n",
      "Epoch 181/300\n",
      "40/40 [==============================] - 0s 183us/step - loss: 185183058.0000 - mse: 185183072.0000\n",
      "Epoch 182/300\n",
      "40/40 [==============================] - 0s 147us/step - loss: 183835356.0000 - mse: 183835360.0000\n",
      "Epoch 183/300\n",
      "40/40 [==============================] - 0s 228us/step - loss: 183052224.0000 - mse: 183052224.0000\n",
      "Epoch 184/300\n",
      "40/40 [==============================] - 0s 175us/step - loss: 182990878.0000 - mse: 182990880.0000\n",
      "Epoch 185/300\n",
      "40/40 [==============================] - 0s 253us/step - loss: 181650124.0000 - mse: 181650128.0000\n",
      "Epoch 186/300\n",
      "40/40 [==============================] - ETA: 0s - loss: 204613456.0000 - mse: 204613456.000 - 0s 218us/step - loss: 181451778.0000 - mse: 181451776.0000\n",
      "Epoch 187/300\n",
      "40/40 [==============================] - 0s 204us/step - loss: 180341976.0000 - mse: 180341984.0000\n",
      "Epoch 188/300\n",
      "40/40 [==============================] - 0s 212us/step - loss: 181039400.0000 - mse: 181039408.0000\n",
      "Epoch 189/300\n",
      "40/40 [==============================] - 0s 213us/step - loss: 179804394.0000 - mse: 179804384.0000\n",
      "Epoch 190/300\n",
      "40/40 [==============================] - 0s 181us/step - loss: 179626784.0000 - mse: 179626784.0000\n",
      "Epoch 191/300\n",
      "40/40 [==============================] - 0s 306us/step - loss: 178024408.0000 - mse: 178024416.0000\n",
      "Epoch 192/300\n",
      "40/40 [==============================] - 0s 136us/step - loss: 177568938.0000 - mse: 177568944.0000\n",
      "Epoch 193/300\n",
      "40/40 [==============================] - 0s 239us/step - loss: 177218380.0000 - mse: 177218384.0000\n",
      "Epoch 194/300\n",
      "40/40 [==============================] - 0s 203us/step - loss: 177032560.0000 - mse: 177032560.0000\n",
      "Epoch 195/300\n",
      "40/40 [==============================] - 0s 226us/step - loss: 176403947.0000 - mse: 176403936.0000\n",
      "Epoch 196/300\n",
      "40/40 [==============================] - 0s 193us/step - loss: 175502100.0000 - mse: 175502112.0000\n",
      "Epoch 197/300\n",
      "40/40 [==============================] - 0s 179us/step - loss: 175569350.0000 - mse: 175569360.0000\n",
      "Epoch 198/300\n",
      "40/40 [==============================] - 0s 226us/step - loss: 176144294.0000 - mse: 176144304.0000\n",
      "Epoch 199/300\n",
      "40/40 [==============================] - 0s 266us/step - loss: 176383142.0000 - mse: 176383152.0000\n",
      "Epoch 200/300\n",
      "40/40 [==============================] - 0s 205us/step - loss: 175261594.0000 - mse: 175261600.0000\n",
      "Epoch 201/300\n",
      "40/40 [==============================] - 0s 175us/step - loss: 173087718.0000 - mse: 173087712.0000\n",
      "Epoch 202/300\n",
      "40/40 [==============================] - 0s 343us/step - loss: 175828960.0000 - mse: 175828960.0000\n",
      "Epoch 203/300\n",
      "40/40 [==============================] - 0s 273us/step - loss: 172241580.0000 - mse: 172241568.0000\n",
      "Epoch 204/300\n",
      "40/40 [==============================] - 0s 295us/step - loss: 171696134.0000 - mse: 171696144.0000\n",
      "Epoch 205/300\n",
      "40/40 [==============================] - 0s 239us/step - loss: 171971502.0000 - mse: 171971504.0000\n",
      "Epoch 206/300\n",
      "40/40 [==============================] - 0s 336us/step - loss: 173177254.0000 - mse: 173177248.0000\n",
      "Epoch 207/300\n",
      "40/40 [==============================] - 0s 295us/step - loss: 171635052.0000 - mse: 171635040.0000\n",
      "Epoch 208/300\n",
      "40/40 [==============================] - 0s 326us/step - loss: 170098270.0000 - mse: 170098256.0000\n",
      "Epoch 209/300\n",
      "40/40 [==============================] - 0s 315us/step - loss: 171902734.0000 - mse: 171902752.0000\n",
      "Epoch 210/300\n",
      "40/40 [==============================] - 0s 277us/step - loss: 170543087.0000 - mse: 170543072.0000\n",
      "Epoch 211/300\n",
      "40/40 [==============================] - 0s 318us/step - loss: 169459840.0000 - mse: 169459840.0000\n",
      "Epoch 212/300\n",
      "40/40 [==============================] - 0s 362us/step - loss: 168966626.0000 - mse: 168966624.0000\n",
      "Epoch 213/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 220us/step - loss: 167981542.0000 - mse: 167981536.0000\n",
      "Epoch 214/300\n",
      "40/40 [==============================] - 0s 260us/step - loss: 168212706.0000 - mse: 168212704.0000\n",
      "Epoch 215/300\n",
      "40/40 [==============================] - 0s 220us/step - loss: 167456960.0000 - mse: 167456944.0000\n",
      "Epoch 216/300\n",
      "40/40 [==============================] - 0s 274us/step - loss: 167354818.0000 - mse: 167354832.0000\n",
      "Epoch 217/300\n",
      "40/40 [==============================] - ETA: 0s - loss: 124496744.0000 - mse: 124496744.000 - 0s 224us/step - loss: 166597186.0000 - mse: 166597200.0000\n",
      "Epoch 218/300\n",
      "40/40 [==============================] - 0s 599us/step - loss: 166410070.0000 - mse: 166410064.0000\n",
      "Epoch 219/300\n",
      "40/40 [==============================] - 0s 319us/step - loss: 166362786.0000 - mse: 166362784.0000\n",
      "Epoch 220/300\n",
      "40/40 [==============================] - 0s 374us/step - loss: 167367390.0000 - mse: 167367392.0000\n",
      "Epoch 221/300\n",
      "40/40 [==============================] - 0s 659us/step - loss: 165864552.0000 - mse: 165864544.0000\n",
      "Epoch 222/300\n",
      "40/40 [==============================] - 0s 417us/step - loss: 164974476.0000 - mse: 164974480.0000\n",
      "Epoch 223/300\n",
      "40/40 [==============================] - 0s 435us/step - loss: 164601956.0000 - mse: 164601952.0000\n",
      "Epoch 224/300\n",
      "40/40 [==============================] - 0s 420us/step - loss: 165287576.0000 - mse: 165287584.0000\n",
      "Epoch 225/300\n",
      "40/40 [==============================] - 0s 265us/step - loss: 164031538.0000 - mse: 164031536.0000\n",
      "Epoch 226/300\n",
      "40/40 [==============================] - 0s 380us/step - loss: 163474624.0000 - mse: 163474640.0000\n",
      "Epoch 227/300\n",
      "40/40 [==============================] - 0s 286us/step - loss: 163837160.0000 - mse: 163837152.0000\n",
      "Epoch 228/300\n",
      "40/40 [==============================] - 0s 314us/step - loss: 164269254.0000 - mse: 164269264.0000\n",
      "Epoch 229/300\n",
      "40/40 [==============================] - 0s 237us/step - loss: 163493520.0000 - mse: 163493504.0000\n",
      "Epoch 230/300\n",
      "40/40 [==============================] - ETA: 0s - loss: 248318240.0000 - mse: 248318240.000 - 0s 253us/step - loss: 162456728.0000 - mse: 162456736.0000\n",
      "Epoch 231/300\n",
      "40/40 [==============================] - 0s 253us/step - loss: 162818180.0000 - mse: 162818176.0000\n",
      "Epoch 232/300\n",
      "40/40 [==============================] - 0s 329us/step - loss: 161849486.0000 - mse: 161849488.0000\n",
      "Epoch 233/300\n",
      "40/40 [==============================] - 0s 297us/step - loss: 161748130.0000 - mse: 161748128.0000\n",
      "Epoch 234/300\n",
      "40/40 [==============================] - 0s 304us/step - loss: 161181396.0000 - mse: 161181392.0000\n",
      "Epoch 235/300\n",
      "40/40 [==============================] - 0s 227us/step - loss: 162420144.0000 - mse: 162420128.0000\n",
      "Epoch 236/300\n",
      "40/40 [==============================] - 0s 247us/step - loss: 162031572.0000 - mse: 162031568.0000\n",
      "Epoch 237/300\n",
      "40/40 [==============================] - 0s 234us/step - loss: 161825568.0000 - mse: 161825568.0000\n",
      "Epoch 238/300\n",
      "40/40 [==============================] - 0s 247us/step - loss: 160073476.0000 - mse: 160073472.0000\n",
      "Epoch 239/300\n",
      "40/40 [==============================] - 0s 272us/step - loss: 159813200.0000 - mse: 159813200.0000\n",
      "Epoch 240/300\n",
      "40/40 [==============================] - 0s 213us/step - loss: 160352936.0000 - mse: 160352928.0000\n",
      "Epoch 241/300\n",
      "40/40 [==============================] - 0s 412us/step - loss: 159584222.0000 - mse: 159584224.0000\n",
      "Epoch 242/300\n",
      "40/40 [==============================] - 0s 481us/step - loss: 159949816.0000 - mse: 159949824.0000\n",
      "Epoch 243/300\n",
      "40/40 [==============================] - 0s 339us/step - loss: 160202582.0000 - mse: 160202592.0000\n",
      "Epoch 244/300\n",
      "40/40 [==============================] - 0s 381us/step - loss: 159287808.0000 - mse: 159287808.0000\n",
      "Epoch 245/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 158613890.0000 - mse: 158613888.0000\n",
      "Epoch 246/300\n",
      "40/40 [==============================] - 0s 366us/step - loss: 159075010.0000 - mse: 159075008.0000\n",
      "Epoch 247/300\n",
      "40/40 [==============================] - 0s 498us/step - loss: 159881758.0000 - mse: 159881760.0000\n",
      "Epoch 248/300\n",
      "40/40 [==============================] - 0s 304us/step - loss: 157947272.0000 - mse: 157947264.0000\n",
      "Epoch 249/300\n",
      "40/40 [==============================] - 0s 245us/step - loss: 157617488.0000 - mse: 157617488.0000\n",
      "Epoch 250/300\n",
      "40/40 [==============================] - 0s 329us/step - loss: 158542328.0000 - mse: 158542336.0000\n",
      "Epoch 251/300\n",
      "40/40 [==============================] - 0s 163us/step - loss: 157531112.0000 - mse: 157531104.0000\n",
      "Epoch 252/300\n",
      "40/40 [==============================] - 0s 260us/step - loss: 157256352.0000 - mse: 157256352.0000\n",
      "Epoch 253/300\n",
      "40/40 [==============================] - 0s 276us/step - loss: 158302378.0000 - mse: 158302384.0000\n",
      "Epoch 254/300\n",
      "40/40 [==============================] - 0s 269us/step - loss: 158157602.0000 - mse: 158157600.0000\n",
      "Epoch 255/300\n",
      "40/40 [==============================] - 0s 257us/step - loss: 156717240.0000 - mse: 156717232.0000\n",
      "Epoch 256/300\n",
      "40/40 [==============================] - 0s 272us/step - loss: 156409696.0000 - mse: 156409696.0000\n",
      "Epoch 257/300\n",
      "40/40 [==============================] - 0s 260us/step - loss: 156061966.0000 - mse: 156061968.0000\n",
      "Epoch 258/300\n",
      "40/40 [==============================] - 0s 267us/step - loss: 156391992.0000 - mse: 156391984.0000\n",
      "Epoch 259/300\n",
      "40/40 [==============================] - 0s 270us/step - loss: 156176822.0000 - mse: 156176816.0000\n",
      "Epoch 260/300\n",
      "40/40 [==============================] - 0s 268us/step - loss: 156214130.0000 - mse: 156214128.0000\n",
      "Epoch 261/300\n",
      "40/40 [==============================] - 0s 246us/step - loss: 155941463.0000 - mse: 155941472.0000\n",
      "Epoch 262/300\n",
      "40/40 [==============================] - 0s 262us/step - loss: 155278204.0000 - mse: 155278192.0000\n",
      "Epoch 263/300\n",
      "40/40 [==============================] - 0s 237us/step - loss: 157804094.0000 - mse: 157804096.0000\n",
      "Epoch 264/300\n",
      "40/40 [==============================] - 0s 212us/step - loss: 160668074.0000 - mse: 160668064.0000\n",
      "Epoch 265/300\n",
      "40/40 [==============================] - 0s 323us/step - loss: 155957544.0000 - mse: 155957552.0000\n",
      "Epoch 266/300\n",
      "40/40 [==============================] - 0s 227us/step - loss: 154842069.0000 - mse: 154842064.0000\n",
      "Epoch 267/300\n",
      "40/40 [==============================] - 0s 272us/step - loss: 154811476.0000 - mse: 154811488.0000\n",
      "Epoch 268/300\n",
      "40/40 [==============================] - 0s 307us/step - loss: 154571358.0000 - mse: 154571360.0000\n",
      "Epoch 269/300\n",
      "40/40 [==============================] - 0s 310us/step - loss: 154650662.0000 - mse: 154650656.0000\n",
      "Epoch 270/300\n",
      "40/40 [==============================] - 0s 242us/step - loss: 154952965.0000 - mse: 154952960.0000\n",
      "Epoch 271/300\n",
      "40/40 [==============================] - 0s 260us/step - loss: 154381316.0000 - mse: 154381328.0000\n",
      "Epoch 272/300\n",
      "40/40 [==============================] - 0s 225us/step - loss: 155582408.0000 - mse: 155582416.0000\n",
      "Epoch 273/300\n",
      "40/40 [==============================] - 0s 228us/step - loss: 155664454.0000 - mse: 155664448.0000\n",
      "Epoch 274/300\n",
      "40/40 [==============================] - 0s 275us/step - loss: 153783914.0000 - mse: 153783920.0000\n",
      "Epoch 275/300\n",
      "40/40 [==============================] - 0s 431us/step - loss: 153957842.0000 - mse: 153957840.0000\n",
      "Epoch 276/300\n",
      "40/40 [==============================] - 0s 188us/step - loss: 153516452.0000 - mse: 153516448.0000\n",
      "Epoch 277/300\n",
      "40/40 [==============================] - 0s 237us/step - loss: 153713252.0000 - mse: 153713248.0000\n",
      "Epoch 278/300\n",
      "40/40 [==============================] - 0s 324us/step - loss: 153274512.0000 - mse: 153274528.0000\n",
      "Epoch 279/300\n",
      "40/40 [==============================] - 0s 529us/step - loss: 153701186.0000 - mse: 153701200.0000\n",
      "Epoch 280/300\n",
      "40/40 [==============================] - 0s 483us/step - loss: 154406816.0000 - mse: 154406816.0000\n",
      "Epoch 281/300\n",
      "40/40 [==============================] - 0s 284us/step - loss: 153467744.0000 - mse: 153467744.0000\n",
      "Epoch 282/300\n",
      "40/40 [==============================] - 0s 483us/step - loss: 153584664.0000 - mse: 153584656.0000\n",
      "Epoch 283/300\n",
      "40/40 [==============================] - 0s 412us/step - loss: 153795738.0000 - mse: 153795744.0000\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 429us/step - loss: 154073980.0000 - mse: 154073984.0000\n",
      "Epoch 285/300\n",
      "40/40 [==============================] - 0s 576us/step - loss: 153271103.0000 - mse: 153271104.0000\n",
      "Epoch 286/300\n",
      "40/40 [==============================] - 0s 363us/step - loss: 152687374.0000 - mse: 152687376.0000\n",
      "Epoch 287/300\n",
      "40/40 [==============================] - 0s 238us/step - loss: 152342146.0000 - mse: 152342128.0000\n",
      "Epoch 288/300\n",
      "40/40 [==============================] - 0s 206us/step - loss: 152332952.0000 - mse: 152332960.0000\n",
      "Epoch 289/300\n",
      "40/40 [==============================] - 0s 219us/step - loss: 151948576.0000 - mse: 151948576.0000\n",
      "Epoch 290/300\n",
      "40/40 [==============================] - 0s 259us/step - loss: 153219832.0000 - mse: 153219840.0000\n",
      "Epoch 291/300\n",
      "40/40 [==============================] - 0s 303us/step - loss: 152421930.0000 - mse: 152421936.0000\n",
      "Epoch 292/300\n",
      "40/40 [==============================] - 0s 240us/step - loss: 152729412.0000 - mse: 152729424.0000\n",
      "Epoch 293/300\n",
      "40/40 [==============================] - 0s 231us/step - loss: 151994328.0000 - mse: 151994336.0000\n",
      "Epoch 294/300\n",
      "40/40 [==============================] - 0s 225us/step - loss: 151639612.0000 - mse: 151639616.0000\n",
      "Epoch 295/300\n",
      "40/40 [==============================] - 0s 205us/step - loss: 151647791.0000 - mse: 151647792.0000\n",
      "Epoch 296/300\n",
      "40/40 [==============================] - 0s 722us/step - loss: 152277248.0000 - mse: 152277248.0000\n",
      "Epoch 297/300\n",
      "40/40 [==============================] - 0s 264us/step - loss: 151899508.0000 - mse: 151899504.0000\n",
      "Epoch 298/300\n",
      "40/40 [==============================] - 0s 286us/step - loss: 151817590.0000 - mse: 151817584.0000\n",
      "Epoch 299/300\n",
      "40/40 [==============================] - 0s 260us/step - loss: 151821388.0000 - mse: 151821392.0000\n",
      "Epoch 300/300\n",
      "40/40 [==============================] - 0s 249us/step - loss: 151900138.0000 - mse: 151900128.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f54a07ee08>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(x_train,y_train , batch_size = 10,epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119074.33 ],\n",
       "       [119341.73 ],\n",
       "       [125292.914],\n",
       "       [ 62477.54 ],\n",
       "       [170040.86 ],\n",
       "       [122431.945],\n",
       "       [ 52387.977],\n",
       "       [102525.34 ],\n",
       "       [117701.68 ],\n",
       "       [155692.42 ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[103282.38],\n",
       "       [144259.4 ],\n",
       "       [146121.95],\n",
       "       [ 77798.83],\n",
       "       [191050.39],\n",
       "       [105008.31],\n",
       "       [ 81229.06],\n",
       "       [ 97483.56],\n",
       "       [110352.25],\n",
       "       [166187.94]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "accuracy =r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7415537074024752"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.save('regressor.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60066.46]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.predict(np.array([[0,1,0,50000,60000,70000]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
